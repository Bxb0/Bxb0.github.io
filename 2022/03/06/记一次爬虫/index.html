<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/2.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/2.ico"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"bxb0.github.io",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="记一次基本的爬虫。"><meta property="og:type" content="article"><meta property="og:title" content="记一次爬虫"><meta property="og:url" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/index.html"><meta property="og:site_name" content="Bxb0&#39;s blog"><meta property="og:description" content="记一次基本的爬虫。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185109876.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185221096.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185444267.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308190349236.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308191152611.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308191259657.png"><meta property="og:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308194129986.png"><meta property="article:published_time" content="2022-03-06T10:40:47.000Z"><meta property="article:modified_time" content="2022-03-08T13:31:03.253Z"><meta property="article:author" content="ooo"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185109876.png"><link rel="canonical" href="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"en"}</script><title>记一次爬虫 | Bxb0's blog</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="Bxb0's blog" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="Toggle navigation bar"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Bxb0's blog</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i> Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i> Categories<span class="badge">16</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i> Archives<span class="badge">50</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> Search</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="Searching..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en"><link itemprop="mainEntityOfPage" href="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="ooo"><meta itemprop="description" content="0x446e37fb"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Bxb0's blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 记一次爬虫</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">Posted on</span> <time title="Created: 2022-03-06 18:40:47" itemprop="dateCreated datePublished" datetime="2022-03-06T18:40:47+08:00">2022-03-06</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%88%AC%E8%99%AB/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span></span><br><span class="post-meta-item" title="Symbols count in article"><span class="post-meta-item-icon"><i class="far fa-file-word"></i></span> <span class="post-meta-item-text">Symbols count in article:</span> <span>4.3k</span></span><span class="post-meta-item" title="Reading time"><span class="post-meta-item-icon"><i class="far fa-clock"></i></span> <span class="post-meta-item-text">Reading time &asymp;</span> <span>4 mins.</span></span></div></header><div class="post-body" itemprop="articleBody"><p>记一次基本的爬虫。<a id="more"></a></p><h3 id="爬取淘宝搜索某商品出现的信息"><a href="#爬取淘宝搜索某商品出现的信息" class="headerlink" title="爬取淘宝搜索某商品出现的信息"></a>爬取淘宝搜索某商品出现的信息</h3><p>因为淘宝现在要登录才能进行商品搜索，所以我们先在网页上进行登录，然后获取相关的header与cookie，最后利用参数来登录请求相关页面。</p><p>1、登录淘宝</p><p>2、随便搜索某一商品，打开网络资源，刷新一下找到search</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185109876.png" alt="image-20220308185109876"></p><p>3、右键，复制为cURL</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185221096.png" alt="image-20220308185221096"></p><p>4、在 <a href="https://curlconverter.com/" target="_blank" rel="noopener">https://curlconverter.com/</a> 将上一步复制的curl访问命令转化为python的请求方式。</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308185444267.png" alt="image-20220308185444267"></p><p>5、复制出上一步转化得到的python请求代码，补充好相关请求和解析数据的代码即可。</p><p>完整代码：url中的s参数表示正在访问的页面</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=GBK</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_html</span><span class="params">()</span>:</span></span><br><span class="line">    name = <span class="string">"休闲养生食品"</span></span><br><span class="line">    start_url = <span class="string">'https://s.taobao.com/search?q=&#123;&#125;&amp;s='</span>.format(name)</span><br><span class="line">    header = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:70.0) Gecko/20100101 Firefox/70.0'</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cookies = &#123;<span class="string">''</span>&#125; <span class="comment">#登录后从网络资源中获取</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:97.0) Gecko/20100101 Firefox/97.0'</span>,</span><br><span class="line">        <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Upgrade-Insecure-Requests'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'Sec-Fetch-Dest'</span>: <span class="string">'document'</span>,</span><br><span class="line">        <span class="string">'Sec-Fetch-Mode'</span>: <span class="string">'navigate'</span>,</span><br><span class="line">        <span class="string">'Sec-Fetch-Site'</span>: <span class="string">'none'</span>,</span><br><span class="line">        <span class="string">'Sec-Fetch-User'</span>: <span class="string">'?1'</span>,</span><br><span class="line">        <span class="string">'Cache-Control'</span>: <span class="string">'max-age=0'</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pages = <span class="number">100</span></span><br><span class="line">    goods = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(pages)):</span><br><span class="line">        url = start_url + str(i*<span class="number">44</span>)</span><br><span class="line">        print(url)</span><br><span class="line">        r = requests.get(url, headers=headers, cookies=cookies, timeout=<span class="number">60</span>)</span><br><span class="line">        <span class="keyword">assert</span> r.status_code == <span class="number">200</span></span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        goods += r.text</span><br><span class="line">        <span class="comment">#print(r.text)</span></span><br><span class="line">        print(<span class="string">"爬取进度: %d%%"</span>%(((i+<span class="number">1</span>)/pages)*<span class="number">100</span>))</span><br><span class="line">        <span class="comment">#exit()</span></span><br><span class="line">    <span class="comment">#print(goods)</span></span><br><span class="line">    <span class="keyword">return</span> goods</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_ms</span><span class="params">(html)</span>:</span></span><br><span class="line">    titles = re.findall(<span class="string">'"raw_title":"(.*?)"'</span>, html)</span><br><span class="line">    pays = re.findall(<span class="string">'"view_sales":"(.*?)人付款"'</span>, html)</span><br><span class="line">    pays = [i.replace(<span class="string">'+'</span>, <span class="string">''</span>) <span class="keyword">for</span> i <span class="keyword">in</span> pays]</span><br><span class="line">    pays = [i.replace(<span class="string">'万'</span>, <span class="string">'0000'</span>) <span class="keyword">if</span> i.find(<span class="string">'万'</span>) != <span class="number">-1</span> <span class="keyword">else</span> i <span class="keyword">for</span> i <span class="keyword">in</span> pays]</span><br><span class="line">    <span class="comment">#print(pays)</span></span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(titles)):</span><br><span class="line">        data.append([titles[i], pays[i]])</span><br><span class="line">    <span class="comment">#print(data)    </span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_file</span><span class="params">(data)</span>:</span></span><br><span class="line">    path = <span class="string">'data_taobao.csv'</span></span><br><span class="line">    f = open(path, <span class="string">"w"</span>, newline=<span class="string">""</span>)</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    writer.writerow([<span class="string">'商品'</span>, <span class="string">'付款人数'</span>])</span><br><span class="line">    writer.writerows(data)</span><br><span class="line">    f.close()</span><br><span class="line">  </span><br><span class="line">goods = get_html()</span><br><span class="line">data = find_ms(goods)</span><br><span class="line">save_file(data)</span><br></pre></td></tr></table></figure><h3 id="爬取知乎中搜索某话题的综合相关内容"><a href="#爬取知乎中搜索某话题的综合相关内容" class="headerlink" title="爬取知乎中搜索某话题的综合相关内容"></a>爬取知乎中搜索某话题的综合相关内容</h3><p>如搜索朋克养生，要爬取的页面如下：</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308190349236.png" alt="image-20220308190349236"></p><p>因为是第一次接触爬虫，以为简单的把页面数据请求下来使用正则匹配需要的内容就好了，但发现请求的内容根本没有页面展示出的相关内容，只有一个框架。</p><p>经过相关了解后，发现这是一个使用ajax异步加载的页面，也就是说我们需要的数据是在访问页面过程中动态加载的，我们在脚本中请求只能获得静态页面（由于requests模块是一个不完全模拟浏览器行为的模块，只能爬取到网页的HTML文档信息，无法解析和执行CSS、JavaScript代码），接着我从网络资源中的xhr页面中找到真正获取数据的接口：</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308191152611.png" alt="image-20220308191152611"></p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308191259657.png" alt="image-20220308191259657"></p><p>但是直接请求这个接口服务端并不会正确返回，因为有相关字段（x-zse-93，x-zse-96，x-zse-81）进行校验，这也简单，其中x-zse-93与x-zse-81是固定的，我们只需要从js代码中逆向出x-zse-96的计算方法，爬取页面的时候模拟计算一下就好。而弄完，又遇到了其它的问题，访问接口的search_hash_id不止一种，这就使x-zse-96字段的值也不止一种，且相关处理也挺麻烦的，因此我使用了另外一种爬取方法：<strong>使用selenium接管本地打开的浏览器然后利用执行js代码对页面滚动条进行滑动，最后获取匹配我们需要的关键信息。（知乎对selenium进行了反爬处理，即对相关字符串进行了检查）</strong></p><p>1、本地以一个端口启动chorm</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chrome.exe <span class="attribute">--remote-debugging-port</span>=9222 <span class="attribute">--user-data-dir</span>=<span class="string">"./"</span></span><br></pre></td></tr></table></figure><p>2、使用selenium接管上一步打开的浏览器，访问要爬取页面的url</p><p>3、利用执行js代码的方式不断向下滑动滚动条加载数据，不断加大滚动条与顶部的距离</p><p><img src="/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/image-20220308194129986.png" alt="image-20220308194129986"></p><p>4、利用相关标签匹配所需要的数据并进行正则匹配</p><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=gbk</span></span><br><span class="line"><span class="keyword">import</span> selenium.webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_data</span><span class="params">(driver, xpath, data)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> driver.find_elements(by=By.XPATH, value=xpath):</span><br><span class="line">        tmp = []</span><br><span class="line">        tmp += [content.find_element(by=By.CLASS_NAME, value=<span class="string">"Highlight"</span>).text]</span><br><span class="line">        ans = list(re.findall(<span class="string">"赞同.?(.*?)\n([0-9]*).*\n(.*)"</span>, content.find_element(by=By.CLASS_NAME, value=<span class="string">"ContentItem-actions"</span>).text)[<span class="number">0</span>])</span><br><span class="line">        tmp += [<span class="string">'0'</span> <span class="keyword">if</span> i == <span class="string">''</span> <span class="keyword">else</span> i <span class="keyword">for</span> i <span class="keyword">in</span> ans]</span><br><span class="line">        data += [tmp]</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(data)</span>:</span></span><br><span class="line">    name = <span class="string">"朋克养生"</span></span><br><span class="line">    url = <span class="string">'https://www.zhihu.com/search?q=&#123;&#125;&amp;utm_content=search_history&amp;type=content'</span>.format(name)</span><br><span class="line">    chrome_options = Options()</span><br><span class="line">    chrome_options.add_experimental_option(<span class="string">"debuggerAddress"</span>, <span class="string">"127.0.0.1:9222"</span>)</span><br><span class="line">    driver = selenium.webdriver.Chrome(options=chrome_options)</span><br><span class="line">    driver.get(url)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        js = <span class="string">'var action=document.documentElement.scrollTop=&#123;&#125;'</span>.format(<span class="number">1000</span>+<span class="number">300</span>*i)</span><br><span class="line">        driver.execute_script(js)</span><br><span class="line">        print(<span class="string">"爬取进度: %d%%"</span>%(((<span class="number">1000</span>+<span class="number">300</span>*i)/(<span class="number">1000</span>+<span class="number">300</span>*<span class="number">99</span>))*<span class="number">100</span>))</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    match_data(driver, <span class="string">"//div[@class='ContentItem AnswerItem']"</span>, data)</span><br><span class="line">    match_data(driver, <span class="string">"//div[@class='ContentItem ArticleItem']"</span>, data)   </span><br><span class="line">      </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_file</span><span class="params">(data)</span>:</span></span><br><span class="line">    path = <span class="string">'data_zhihu.csv'</span></span><br><span class="line">    f = open(path, <span class="string">"w"</span>, newline=<span class="string">""</span>)</span><br><span class="line">    writer = csv.writer(f)</span><br><span class="line">    writer.writerow([<span class="string">'问题'</span>, <span class="string">'点赞数'</span>, <span class="string">'评论数'</span>, <span class="string">'日期'</span>])</span><br><span class="line">    writer.writerows(data)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data = []  </span><br><span class="line">    get_data(data)</span><br><span class="line">    article_num = len(data)</span><br><span class="line">    voteup_sum = sum([int(i[<span class="number">1</span>].replace(<span class="string">' 万'</span>, <span class="string">'0000'</span>)) <span class="keyword">if</span> <span class="string">'万'</span> <span class="keyword">in</span> i[<span class="number">1</span>] <span class="keyword">else</span> int(i[<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">    comment_sum = sum([int(i[<span class="number">2</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> data])</span><br><span class="line">    print(<span class="string">"爬取完成，文章总数: %d, 点赞总数: %d, 评论总数: %d"</span>%(article_num, voteup_sum, comment_sum))</span><br><span class="line">    save_file(data)</span><br></pre></td></tr></table></figure></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>Post author:</strong> ooo</li><li class="post-copyright-link"> <strong>Post link:</strong> <a href="https://bxb0.github.io/2022/03/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%88%AC%E8%99%AB/" title="记一次爬虫">https://bxb0.github.io/2022/03/06/记一次爬虫/</a></li><li class="post-copyright-license"> <strong>Copyright Notice:</strong> All articles in this blog are licensed under<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> unless stating additionally.</li></ul></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-item"><a href="/2022/03/02/SUSCTF-2022%E9%83%A8%E5%88%86%E9%80%86%E5%90%91%E9%A2%98%E8%A7%A3/" rel="prev" title="SUSCTF 2022部分逆向题解"><i class="fa fa-chevron-left"></i> SUSCTF 2022部分逆向题解</a></div><div class="post-nav-item"> <a href="/2022/03/08/pragyan-ctf-2022/" rel="next" title="pragyan-ctf-2022">pragyan-ctf-2022<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> Table of Contents</li><li class="sidebar-nav-overview"> Overview</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#爬取淘宝搜索某商品出现的信息"><span class="nav-number">1.</span> <span class="nav-text">爬取淘宝搜索某商品出现的信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#爬取知乎中搜索某话题的综合相关内容"><span class="nav-number">2.</span> <span class="nav-text">爬取知乎中搜索某话题的综合相关内容</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">ooo</p><div class="site-description" itemprop="description">0x446e37fb</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">50</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">16</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">3</span> <span class="site-state-item-name">tags</span></a></div></nav></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i> Links</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://i0gan.github.io/" title="https:&#x2F;&#x2F;i0gan.github.io&#x2F;" rel="noopener" target="_blank">i0gan</a></li><li class="links-of-blogroll-item"> <a href="http://pipinstall.cn/" title="http:&#x2F;&#x2F;pipinstall.cn" rel="noopener" target="_blank">ttfpx</a></li><li class="links-of-blogroll-item"> <a href="https://vino0o0o.github.io/" title="https:&#x2F;&#x2F;vino0o0o.github.io&#x2F;" rel="noopener" target="_blank">Vino0o0o</a></li><li class="links-of-blogroll-item"> <a href="https://github.com/Firebasky" title="https:&#x2F;&#x2F;github.com&#x2F;Firebasky" rel="noopener" target="_blank">Firebasky</a></li><li class="links-of-blogroll-item"> <a href="http://xuan.pipinstall.cn/" title="http:&#x2F;&#x2F;xuan.pipinstall.cn&#x2F;" rel="noopener" target="_blank">xuan</a></li><li class="links-of-blogroll-item"> <a href="https://hack-for.fun/" title="https:&#x2F;&#x2F;hack-for.fun&#x2F;" rel="noopener" target="_blank">M0nk3y</a></li><li class="links-of-blogroll-item"> <a href="http://happi0.gitee.io/" title="http:&#x2F;&#x2F;happi0.gitee.io&#x2F;" rel="noopener" target="_blank">happi0</a></li><li class="links-of-blogroll-item"> <a href="https://the_itach1.gitee.io/" title="https:&#x2F;&#x2F;the_itach1.gitee.io&#x2F;" rel="noopener" target="_blank">The_Itach1</a></li></ul></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2022</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">ooo</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-chart-area"></i></span> <span class="post-meta-item-text">Symbols count total:</span> <span title="Symbols count total">411k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span class="post-meta-item-text">Reading time total &asymp;</span> <span title="Reading time total">6:14</span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/javascript" src="/js/src/clicklove.js"></script><script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"left",width:150,height:300},mobile:{show:!0},log:!1})</script></body></html>